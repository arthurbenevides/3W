df = pd.read_csv("Documents/Arthur/WELL-00006_20180617181315.csv") 
df = df.drop(['timestamp', 'T-JUS-CKGL'], axis=1) 

# Separar os dados
df_class_0 = df[df['class'] == 0]
df_class_0 = df_class_0.sample(n=3000, random_state=42)

df_class_107 = df[df['class'] == 107] 
df_class_107 = df_class_107.sample(n=3000, random_state=42)
 
df_class_7 = df[df['class'] == 7] 

df_train = pd.concat([df_class_0, df_class_107, df_class_7], ignore_index=True) 


# Parâmetros para o janelamento 
win_len = 180 
stride = 50  


# Listas para armazenar as janelas e os rótulos 
x_class_0 = []
y_class_0 = [] 

for k in df_train['class'].unique(): 

    df_temp_2 = df_train[df_train['class'] == k] 

    for i in np.arange(0, len(df_temp_2)-(win_len), stride): 

        temp = df_temp_2.iloc[i:i+win_len, :-1].values 

        temp = temp.reshape((1, -1)) 

        print(temp) 

        x_class_0.append(temp) 

        y_class_0.append(df_temp_2.iloc[i+win_len, -1]) 

x_class_0 = np.array(x_class_0) 
x_class_0 = x_class_0.reshape((x_class_0.shape[0], x_class_0.shape[2])) 
y_class_0 = np.array(y_class_0) 
 
encoder = LabelEncoder() 
encoder.fit(y_class_0) 
encoded_y = encoder.transform(y_class_0) 
OHE_y = to_categorical(encoded_y, num_classes=3) 

 
# Seed para controlar a aleatoriedade a cada rodada de código 
seed_value = 100 
np.random.seed(seed_value) 

def extract_mean(x): 
    return np.mean(x, axis=1) 

def extract_median(x): 
    return np.median(x, axis=1) 

def extract_max(x): 
    return np.max(x, axis=1) 

def extract_min(x): 
    return np.min(x, axis=1) 

def extract_var(x): 
    return np.var(x, axis=1) 

def extract_std(x): 
    return np.std(x, axis=1) 


MEAN = extract_mean(x_class_0) 
# MEDIAN = extract_median(x_class_0) 
# MAX = extract_max(x_class_0) 
# MIN = extract_min(x_class_0) 
VAR = extract_var(x_class_0) 
# STD = extract_std(x_class_0) 

df_features = pd.DataFrame({'Mean': MEAN, 'Var': VAR}) 
x = df_features.values 

x_train, x_test, y_train, y_test = train_test_split(
    x, OHE_y, test_size=0.3, shuffle=True, random_state=seed_value) 


 
def prepare_quantum_dataset(x): 
    q = cirq.GridQubit.rect(1, len(x))  
    ops = [cirq.ry(2* x[i]).on(q[i]) for i in range(len(x))] 
    circuit = cirq.Circuit(ops) 
    return circuit 

x_train_q = [prepare_quantum_dataset(x) for x in x_train] 
x_test_q = [prepare_quantum_dataset(x) for x in x_test] 
 
print(x_train_q[0]) 
SVGCircuit(x_train_q[0]) 

 
# Definir a quantidade de camadas e qubits 
n_layers = 1 
qubits = 2

params = sympy.symbols('a b c')   
q = cirq.GridQubit.rect(1, qubits) 
ops = []  

 
for j in range(n_layers): 
  for i in range(qubits): 
      ops.append(cirq.ry(params[0]).on(q[i]))  
      ops.append(cirq.rz(params[1]).on(q[i])) 
      ops.append(cirq.ry(params[2]).on(q[i])) 

  ops.append(cirq.CZ(q[0], q[1])) 
  ops.append(cirq.CZ(q[1], q[0]))


model_circuit = cirq.Circuit(ops) 
SVGCircuit(model_circuit)  
 
es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience = 10) 
import time 
start = time.time() 

nn = tf.keras.Sequential([tf.keras.layers.Dense(30,activation = 'relu'), tf.keras.layers.Dense(3,activation = 'softmax')]) #sigmoid // softmax 

circuit_input = tf.keras.Input(shape = (), dtype = tf.string, name = 'circuits_input') 

measurement_ops = [cirq.Z(q[i]) for i in range(qubits)]  

circuit_layer = tfq.layers.PQC(model_circuit, measurement_ops) 

model = tf.keras.Model(inputs = circuit_input, outputs = nn(circuit_layer(circuit_input))) 

optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01) 

model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])#,'Precision','recall', 'f1score']) 

history = model.fit(x = tfq.convert_to_tensor(x_train_q), y = y_train, epochs = 200, verbose = 1, validation_split = 0.2, callbacks=[es]) 

 
# Test set evaluation 
loss, acc = model.evaluate(tfq.convert_to_tensor(x_test_q), y_test, verbose = 2) 
end = time.time() 
print("Run time:", end - start) 


# Evaluate the model on the test dataset 
y_test_ne = np.argmax(y_test, axis = 1) 
y_test_pred_ne = np.argmax(model.predict(tfq.convert_to_tensor(x_test_q)), axis = 1) 
cm = confusion_matrix(y_test_ne, y_test_pred_ne) 
print(cm) 


# Plot the confusion matrix 
import seaborn as sns 
ax = sns.heatmap(cm, annot=True, cmap='Blues') 
ax.set_title('3W Test'); 
ax.set_xlabel('\nPredicted Label') 
ax.set_ylabel('True Label'); 


## Display the visualization of the Confusion Matrix. 
plt.show() 

# Classification report (test set) 
from sklearn.metrics import classification_report 
class_report_best = classification_report(y_pred = y_test_pred_ne , y_true = y_test_ne, digits = 4) 
print(class_report_best) 
runtime = end - start 
print(runtime) 

# Loss plot 
plt.plot(history.history['loss']) 
plt.plot(history.history['val_loss']) 
plt.title("CWRU Classification Case Study") 
plt.xlabel("Epochs") 
plt.ylabel("Loss") 
plt.legend(['train', 'validation'], loc='upper right') 
plt.grid() 
plt.show()

# Accuracy plot 
plt.plot(history.history['accuracy']) 
plt.plot(history.history['val_accuracy']) 
plt.title("CWRU Classification Case Study") 
plt.xlabel("Epochs") 
plt.ylabel("Accuracy") 
plt.legend(['train', 'validation'], loc='lower right') 
plt.grid() 
plt.show()
